{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      # To use np.arrays\n",
    "import pandas as pd     # To use dataframes\n",
    "\n",
    "# To plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set = pd.read_csv('Pump_it_Up_Data_Mining_the_Water_Table_-_Training_set_values.csv') # train set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labels = pd.read_csv('Pump_it_Up_Data_Mining_the_Water_Table_-_Training_set_labels.csv') #train set labels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set.set_index('id',inplace=True) # setting id as an index to train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_labels.set_index('id',inplace=True) # setting id as an index to train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_train_labels, df_train_set, how = 'inner', left_index = True,right_index=True) #merging two data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True) # setting a new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['decade'] = df['construction_year'] #creating new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9188\\2473028233.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['decade'].replace(to_replace = (1960,1961,1962,1963,1964,1965,1966,1967,1968,1969),\n"
     ]
    }
   ],
   "source": [
    "df['decade'].replace(to_replace = (1960,1961,1962,1963,1964,1965,1966,1967,1968,1969),\n",
    "                        value ='60s' , inplace=True)\n",
    "df['decade'].replace(to_replace = (1970,1971,1972,1973,1974,1975,1976,1977,1978,1979),\n",
    "                        value ='70s' , inplace=True)\n",
    "df['decade'].replace(to_replace = (1980,1981,1982,1983,1984,1985,1986,1987,1988,1989),\n",
    "                        value ='80s' , inplace=True)\n",
    "df['decade'].replace(to_replace = (1990,1991,1992,1993,1994,1995,1996,1997,1998,1999),\n",
    "                        value ='90s' , inplace=True)\n",
    "df['decade'].replace(to_replace = (2000,2001,2002,2003,2004,2005,2006,2007,2008,2009),\n",
    "                        value ='00s' , inplace=True)\n",
    "df['decade'].replace(to_replace = (2010,2011,2012,2013),\n",
    "                        value ='10s' , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the names of the columns you want to drop\n",
    "columns_to_drop = ['id', 'installer','longitude','latitude','wpt_name','num_private','subvillage','region','lga',\n",
    "                   'ward','recorded_by','scheme_name', 'extraction_type_group' ,'management_group','payment_type',\n",
    "                   'water_quality','source_type', 'quantity_group' , 'waterpoint_type']\n",
    "\n",
    "# Drop the specified columns\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':  # Categorical columns\n",
    "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "    else:  # Numerical columns\n",
    "        data[column].fillna(data[column].mean(), inplace=True)\n",
    "\n",
    "# Verify that missing values have been handled\n",
    "print(\"\\nMissing values count in each column after handling:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler #numrical\n",
    "\n",
    "\n",
    "# Identify numerical features\n",
    "numerical_features = data.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Specify the desired range for normalization\n",
    "desired_range = (0, 1)  # Adjust as needed\n",
    "\n",
    "# Scale numerical features using MinMaxScaler with adjusted range\n",
    "minmax_scaler = MinMaxScaler(feature_range=desired_range)\n",
    "data[numerical_features] = minmax_scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "# Display the DataFrame with scaled features within the adjusted range\n",
    "print(\"DataFrame with scaled features within the adjusted range:\")\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import category_encoders as ce #kalam categories kolo ma 3ada akher col\n",
    "\n",
    "\n",
    "# Identify the categorical columns (excluding the last column, which is the target variable)\n",
    "categorical_columns = data.iloc[:, :-1].select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize the Ordinal Encoder\n",
    "ordinal_encoder = ce.OrdinalEncoder(cols=categorical_columns)\n",
    "\n",
    "# Apply ordinal encoding to the categorical columns\n",
    "data = ordinal_encoder.fit_transform(data)\n",
    "\n",
    "# Display the dataset with ordinal encoded features\n",
    "print(\"\\nDataset with Ordinal Encoded Features:\")\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #akher col\n",
    "\n",
    "\n",
    "# Identify the last column of the DataFrame\n",
    "last_column = data.columns[-1]\n",
    "\n",
    "# Perform label encoding on the last column\n",
    "label_encoder = LabelEncoder()\n",
    "data = data.copy()  # Make a copy of the original DataFrame to preserve it\n",
    "data[last_column] = label_encoder.fit_transform(data[last_column])\n",
    "\n",
    "# Display the DataFrame with all columns encoded\n",
    "print(\"DataFrame with all columns encoded:\")\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
